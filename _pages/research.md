---
layout: archive
title: "Research Experience"
permalink: /research/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}
# Canonical correlation analysis as reduced rank regression
**2023 – 2024, University of Toronto, Toronto, Canada**

![Canonical correlation analysis](path_to_image)

**Description:** The emergence of high-dimensional datasets presents significant challenges for traditional CCA frameworks, as traditional estimates of the canonical directions cease to be consistent. We propose a novel approach that attempts to narrow the gap between theory and practice in high-dimensional CCA in the case where one dataset is high-dimensional and the other is not. By incorporating concepts from reduced rank regression and sparse estimation, we are able to establish theoretical bounds for our procedure, ensuring statistical rigor while maintaining computational efficiency — making it an attractive option for the analysis of large datasets.

**Collaborators:** Claire Donnat.

[Paper](#) [Slides](#)

---

# Multi-period forecasting
**2021 – 2022, Stanford University, Stanford, USA**

![Multi-period forecasting](path_to_image)

**Description:** Forecasting methodologies have always attracted a lot of attention and have become an especially hot topic since the beginning of the COVID-19 pandemic. In this paper, we consider the problem of multi-period forecasting that aims to predict several horizons at once. We propose a novel approach that forces the prediction to be “smooth” across horizons and apply it to two tasks: point estimation via regression and interval prediction via quantile regression. This methodology was developed for real-time distributed COVID-19 forecasting. This project was sponsored by Stanford Data Science Institute.

**Collaborators:** Trevor Hastie, Rob Tibshirani, Delphi Research Group.

[Paper](#) [Slides](#) [Code](#)

---

# Weighted low rank matrix approximation
**2020 – present, Stanford University, Stanford, USA**

![Weighted low rank matrix approximation](path_to_image)

**Description:** Low-rank matrix approximation is one of the central concepts in machine learning, with applications in dimension reduction, de-noising, multivariate statistical methodology, and many more. A recent extension to LRMA is called low-rank matrix completion (LRMC). It solves the LRMA problem when some observations are missing and is especially useful for recommender systems. In this project, we consider an element-wise weighted generalization of LRMA. WLRMA has many applications. For example, it is ...

[Paper](#) [Slides](#) [Code](#)



